{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "from datasets import Dataset\n",
    "from transformers import AutoProcessor \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T00:56:02.576410Z",
     "start_time": "2024-09-24T00:56:00.767556Z"
    }
   },
   "id": "22e159e469bc58fd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_file_names = []\n",
    "\n",
    "for root, dirnames, filenames in os.walk(\"./ARC-AGI-master/data/training\"):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.json'):\n",
    "            train_file_names.append(filename)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T00:56:02.580100Z",
     "start_time": "2024-09-24T00:56:02.577106Z"
    }
   },
   "id": "8a19e73c3abf46d5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def grid2str(grid):\n",
    "    return \"\\n\".join(\" \".join(str(i) for i in j) for j in grid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:08.004567Z",
     "start_time": "2024-09-24T01:22:08.002916Z"
    }
   },
   "id": "2979514aabe243e8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "bunch_of_series = []\n",
    "i = 0\n",
    "\n",
    "for name in train_file_names:\n",
    "    with open(f\"./ARC-AGI-master/data/training/{name}\") as temp_file:\n",
    "        some_file = json.load(temp_file)\n",
    "        \n",
    "        try:\n",
    "            prob_ex_3_placement_input = grid2str(some_file[\"train\"][2][\"input\"])\n",
    "            prob_ex_3_placement_output = grid2str(some_file[\"train\"][2][\"output\"])\n",
    "        #print(i)\n",
    "        except IndexError:\n",
    "            prob_ex_3_placement_input = \"\"\n",
    "            prob_ex_3_placement_output = \"\"\n",
    "            \n",
    "        try:\n",
    "            prob_ex_4_placement_input = grid2str(some_file[\"train\"][3][\"input\"])\n",
    "            prob_ex_4_placement_output = grid2str(some_file[\"train\"][3][\"output\"])\n",
    "        except IndexError:\n",
    "            prob_ex_4_placement_input = \"\"\n",
    "            prob_ex_4_placement_output = \"\"\n",
    "            \n",
    "        try:\n",
    "            problem_test_2_placement_input = grid2str(some_file[\"test\"][1][\"input\"])\n",
    "            problem_test_2__placement_output = grid2str(some_file[\"test\"][1][\"output\"])\n",
    "        except IndexError:\n",
    "            problem_test_2_placement_input = \"\"\n",
    "            problem_test_2__placement_output = \"\"\n",
    "        \n",
    "        temp_series = pd.Series({\n",
    "            \"problem_id\": name,\n",
    "            \"problem_example_1_input\":  grid2str(some_file[\"train\"][0][\"input\"]),\n",
    "            \"problem_example_1_output\": grid2str(some_file[\"train\"][0][\"output\"]),\n",
    "            \"problem_example_2_input\":  grid2str(some_file[\"train\"][1][\"input\"]),\n",
    "            \"problem_example_2_output\": grid2str(some_file[\"train\"][1][\"output\"]),\n",
    "            \"problem_example_3_input\":  prob_ex_3_placement_input,\n",
    "            \"problem_example_3_output\": prob_ex_3_placement_output,\n",
    "            \"problem_example_4_input\":  prob_ex_4_placement_input, \n",
    "            \"problem_example_4_output\": prob_ex_4_placement_output,\n",
    "            \"problem_test_1_input\":     grid2str(some_file[\"test\"][0][\"input\"]),\n",
    "            \"problem_test_1_output\":    grid2str(some_file[\"test\"][0][\"output\"]),\n",
    "            \"problem_test_2_input\":     problem_test_2_placement_input,\n",
    "            \"problem_test_2_output\":    problem_test_2__placement_output,\n",
    "        })\n",
    "        \n",
    "        i += 1\n",
    "        bunch_of_series.append(temp_series)\n",
    "        \n",
    "arc_train = pd.concat(bunch_of_series, axis=1).T\n",
    "arc_no_id = arc_train.loc[:, arc_train.columns != \"problem_id\"]\n",
    "arc_no_id_hf = Dataset.from_pandas(arc_no_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:08.473499Z",
     "start_time": "2024-09-24T01:22:08.237455Z"
    }
   },
   "id": "ad434fc7319d1fa0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [{'input': [[0, 0, 5], [0, 5, 0], [5, 0, 0]], 'output': [[3, 3, 3], [4, 4, 4], [2, 2, 2]]}, {'input': [[0, 0, 5], [0, 0, 5], [0, 0, 5]], 'output': [[3, 3, 3], [3, 3, 3], [3, 3, 3]]}, {'input': [[5, 0, 0], [0, 5, 0], [5, 0, 0]], 'output': [[2, 2, 2], [4, 4, 4], [2, 2, 2]]}, {'input': [[0, 5, 0], [0, 0, 5], [0, 5, 0]], 'output': [[4, 4, 4], [3, 3, 3], [4, 4, 4]]}], 'test': [{'input': [[0, 0, 5], [5, 0, 0], [0, 5, 0]], 'output': [[3, 3, 3], [2, 2, 2], [4, 4, 4]]}]}\n"
     ]
    }
   ],
   "source": [
    "with open(f\"./ARC-AGI-master/data/training/{train_file_names[0]}\") as f:\n",
    "    some_file = json.load(f)\n",
    "    print(some_file)\n",
    "    #print(grid2str(some_file[\"test\"][0][\"input\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:08.481343Z",
     "start_time": "2024-09-24T01:22:08.474601Z"
    }
   },
   "id": "343529b39172ca9c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'a85d4709.json'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_names[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:09.189794Z",
     "start_time": "2024-09-24T01:22:09.185531Z"
    }
   },
   "id": "d710663e2f5c5351"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", \n",
    "# trust_remote_code=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", \n",
    "# trust_remote_code=True)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-vision-instruct\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-MoE-instruct\",                                         trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:09.756252Z",
     "start_time": "2024-09-24T01:22:09.754754Z"
    }
   },
   "id": "4c31512f9323eb50"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three examples of a puzzle — \n",
      "Puzzle 1 input: \n",
      "\n",
      "0 0 5\n",
      "0 5 0\n",
      "5 0 0 \n",
      "\n",
      "Puzzle 1 output: \n",
      "\n",
      "3 3 3\n",
      "4 4 4\n",
      "2 2 2 \n",
      "\n",
      "\n",
      "Puzzle 2 input: \n",
      "\n",
      "0 0 5\n",
      "0 0 5\n",
      "0 0 5 \n",
      "\n",
      "Puzzle 2 output: \n",
      "\n",
      "3 3 3\n",
      "3 3 3\n",
      "3 3 3 \n",
      "\n",
      "\n",
      "Puzzle 3 input: \n",
      "\n",
      "5 0 0\n",
      "0 5 0\n",
      "5 0 0 \n",
      "\n",
      "Puzzle 3 output: \n",
      "\n",
      "2 2 2\n",
      "4 4 4\n",
      "2 2 2 \n",
      "\n",
      "\n",
      "Hint: These puzzles can be imagined as grids and the digits represent different colors. 0: black, 1: blue, 2: red, 3: green, 4: yellow, 5: silver, 6: pink, 7: orange, 8: cyan, 9: brown. Each puzzle-solution pair has some transformation, for instance, adding  a particular digit/color-block in-between two other digits/color-blocks or splitting/combining the size of the overall grid. The solution may not have anything to with the digits themselves or some numerical computations. \n",
      "\n",
      "Based on the examples, could you solve the following test puzzle? \n",
      "\n",
      "0 0 5\n",
      "5 0 0\n",
      "0 5 0 \n",
      "\n",
      "Use chain of thought reasoning, try to identify the pattern, and provide only the final answer to the test puzzle.\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "\n",
    "prompt = (\n",
    "    f\"Here are three examples of a puzzle — \\n\"\n",
    "    f'Puzzle 1 input: \\n\\n{arc_no_id_hf[\"problem_example_1_input\"][num]} \\n\\n'\n",
    "    f'Puzzle 1 output: \\n\\n{arc_no_id_hf[\"problem_example_1_output\"][num]} '\n",
    "    f'\\n\\n\\n'\n",
    "    f'Puzzle 2 input: \\n\\n{arc_no_id_hf[\"problem_example_2_input\"][num]} \\n\\n'\n",
    "    f'Puzzle 2 output: \\n\\n{arc_no_id_hf[\"problem_example_2_output\"][num]} '\n",
    "    f'\\n\\n\\n'\n",
    "    f'Puzzle 3 input: \\n\\n{arc_no_id_hf[\"problem_example_3_input\"][num]} \\n\\n'\n",
    "    f'Puzzle 3 output: \\n\\n{arc_no_id_hf[\"problem_example_3_output\"][num]} '\n",
    "    f'\\n\\n\\n'\n",
    "    \n",
    "    f\"Hint: These puzzles can be imagined as grids and the digits represent different \"\n",
    "    f\"colors. 0: black, 1: blue, 2: red, 3: green, 4: yellow, 5: silver, 6: pink, 7: \"\n",
    "    f\"orange, 8: cyan, 9: brown. Each puzzle-solution pair has some transformation, for \"\n",
    "    f\"instance, adding  a particular digit/color-block in-between two other \"\n",
    "    f\"digits/color-blocks or splitting/combining the size of the overall grid. The \"\n",
    "    f\"solution may not have anything to with the digits themselves or some numerical \"\n",
    "    f\"computations. \\n\\n\"\n",
    "    \n",
    "    f\"Based on the examples, could you solve the following test puzzle? \\n\\n\"\n",
    "    f'{arc_no_id_hf[\"problem_test_1_input\"][num]} \\n\\n'\n",
    "    f'Use chain of thought reasoning, try to identify the pattern, and provide only the '\n",
    "    f'final answer to the test puzzle.'\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "# prompt = f\"Here's three examples of a puzzle \\n\"\n",
    "\n",
    "# for i in range(4):\n",
    "#    prompt += f'Puzzle {i + 1} input: \\n\\n {grid2str\n",
    "#    (arc_no_id_hf[\"problem_example_{i}_input\"][num])}'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:10.090687Z",
     "start_time": "2024-09-24T01:22:10.079243Z"
    }
   },
   "id": "afa64ba89fe901c7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#if tokenizer.pad_token is None:\n",
    "#    tokenizer.pad_token = tokenizer.eos_token\n",
    "#\n",
    "#def chat_with_model(prompt):\n",
    "#    inputs = tokenizer.encode(prompt, return_tensors='pt').to(\"mps\")\n",
    "#    model.to(\"mps\")\n",
    "#    \n",
    "#    output = model.generate(\n",
    "#        inputs, \n",
    "#        max_new_tokens=300,\n",
    "#        pad_token_id=tokenizer.pad_token_id\n",
    "#    )\n",
    "#    \n",
    "#    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#    \n",
    "#    return response #[len(prompt):].strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T20:42:26.317434Z",
     "start_time": "2024-09-23T20:42:26.309227Z"
    }
   },
   "id": "a31846dabe81b39f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#response = chat_with_model(prompt)\n",
    "#print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T20:42:26.610768Z",
     "start_time": "2024-09-23T20:42:26.605366Z"
    }
   },
   "id": "9843f83fa61f4a12"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "2 2 2\n",
      "4 4 4\n"
     ]
    }
   ],
   "source": [
    "print(arc_no_id_hf[\"problem_test_1_output\"][num])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:22:12.836998Z",
     "start_time": "2024-09-24T01:22:12.832654Z"
    }
   },
   "id": "75948349566d9e7d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dc24a2525d64ee494c222a16a7c279d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asteroidhunter/PycharmProjects/fastexps/venv/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x121aefdd0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from unittest.mock import patch\n",
    "# from transformers.dynamic_module_utils import get_imports\n",
    "# \n",
    "# device = \"cpu\"\n",
    "# \n",
    "# def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "#     \"\"\"Work around for https://huggingface.co/microsoft/phi-1_5/discussions/72.\"\"\"\n",
    "#     if not str(filename).endswith(\"/modeling_phimoe.py\"):\n",
    "#         return get_imports(filename)\n",
    "#     imports = get_imports(filename)\n",
    "#     imports.remove(\"flash_attn\")\n",
    "#     return imports\n",
    "\n",
    "model_name = \"microsoft/Phi-3.5-vision-instruct\"\n",
    "\n",
    "# create model\n",
    "#with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    #device_map='auto' if torch.cuda.is_available() else \"mps\",\n",
    "    trust_remote_code=True,\n",
    "    _attn_implementation=\"eager\"\n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_name, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name, \n",
    "#     device_map=\"mps\", \n",
    "#     torch_dtype=\"auto\", \n",
    "#     trust_remote_code=True,\n",
    "#     attn_implementation=\"eager\"\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T00:56:19.708256Z",
     "start_time": "2024-09-24T00:56:11.603356Z"
    }
   },
   "id": "4a0e223aa387fe1a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " By observing the given puzzle and the examples, it appears that the transformation might involve identifying a pattern or color block and then either splitting or combining the overall grid based on that pattern.\n",
      "\n",
      "In the given puzzle, we can see a repeating pattern of \"8 1 8\" and \"8 8 1.\" We can divide the puzzle into two parts:\n",
      "\n",
      "Top half:\n",
      "8 1 8\n",
      "8 8 1\n",
      "\n",
      "Bottom half:\n",
      "8 1 8\n",
      "8 8 1\n",
      "\n",
      "We can see that these patterns are mirror images of each other. Thus, we can create a new grid based on these patterns:\n",
      "\n",
      "8 1\n",
      "8 8\n",
      "\n",
      "So, the final answer for the test puzzle is:\n",
      "\n",
      "8 1\n",
      "8 8\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    #device=\"mps\" # if un-hashed, it drastically worsens model performance\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T22:59:19.228787Z",
     "start_time": "2024-09-23T22:58:37.191863Z"
    }
   },
   "id": "d93727d5113ae404"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|image_1|>\n",
      "<|image_2|>\n",
      "<|image_3|>\n",
      "<|image_4|>\n",
      "<|image_5|>\n",
      "<|image_6|>\n",
      "<|image_7|>\n",
      "<|image_8|>\n",
      "<|image_9|>\n",
      "I will show you several pairs of input and output images representing a puzzle. \n",
      "Each pair demonstrates a pattern or rule. Your task is to analyze these pairs, \n",
      "understand the underlying pattern, and then apply it to a new input to predict its output.\n",
      "\n",
      "Here are the training pairs:\n",
      "1. Input: Image 1, Output: Image 2\n",
      "2. Input: Image 3, Output: Image 4\n",
      "3. Input: Image 5, Output: Image 6\n",
      "4. Input: Image 7, Output: Image 8\n",
      "\n",
      "Now, based on these examples, analyze the test input (Image 9) and describe what \n",
      "the output should look like. Explain your reasoning step by step, and answer the \n",
      "following question: what should the colors be for each of the cells in the test output \n",
      "with 3 x 3 grids?\n",
      "\n",
      "Provide the answer in the form of a grid with digits in place of colors. For reference, \n",
      "0: black, 1: blue, 2: red, 3: green, 4: yellow, 5: silver, 6: pink, 7: orange, 8: cyan,\n",
      " 9: brown.\n"
     ]
    }
   ],
   "source": [
    "def create_vllm_prompt(image_paths):\n",
    "    train_inputs = sorted([p for p in image_paths if 'train_input' in p])\n",
    "    train_outputs = sorted([p for p in image_paths if 'train_output' in p])\n",
    "    test_input = [p for p in image_paths if 'test_input' in p][0] \n",
    "\n",
    "    # image placeholders\n",
    "    placeholders = '\\n'.join(f'<|image_{i+1}|>' for i in range(len(image_paths)))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{placeholders}\n",
    "I will show you several pairs of input and output images representing a puzzle. \n",
    "Each pair demonstrates a pattern or rule. Your task is to analyze these pairs, \n",
    "understand the underlying pattern, and then apply it to a new input to predict its output.\n",
    "\n",
    "Here are the training pairs:\n",
    "1. Input: Image 1, Output: Image 2\n",
    "2. Input: Image 3, Output: Image 4\n",
    "3. Input: Image 5, Output: Image 6\n",
    "4. Input: Image 7, Output: Image 8\n",
    "\n",
    "Now, based on these examples, analyze the test input (Image 9) and describe what \n",
    "the output should look like. Explain your reasoning step by step, and answer the \n",
    "following question: what should the colors be for each of the cells in the test output \n",
    "with 3 x 3 grids?\n",
    "\n",
    "Provide the answer in the form of a grid with digits in place of colors. For reference, \n",
    "0: black, 1: blue, 2: red, 3: green, 4: yellow, 5: silver, 6: pink, 7: orange, 8: cyan,\n",
    " 9: brown.\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "image_paths = [\n",
    "    './images_for_vllm/train_input_0.png',\n",
    "    './images_for_vllm/train_output_0.png',\n",
    "    './images_for_vllm/train_input_1.png',\n",
    "    './images_for_vllm/train_output_1.png',\n",
    "    './images_for_vllm/train_input_2.png',\n",
    "    './images_for_vllm/train_output_2.png',\n",
    "    './images_for_vllm/train_input_3.png',\n",
    "    './images_for_vllm/train_output_3.png',\n",
    "    './images_for_vllm/test_input_0.png'\n",
    "]\n",
    "\n",
    "prompt = create_vllm_prompt(image_paths)\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:37:48.889863Z",
     "start_time": "2024-09-24T01:37:48.885884Z"
    }
   },
   "id": "2d56b8b633710a1e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this puzzle, we need to identify the pattern or rule that transforms the input image into the output image. Let's analyze the given pairs:\n",
      "\n",
      "1. Input: Image 1 (black and white checkerboard)\n",
      "   Output: Image 2 (green and yellow gradient)\n",
      "\n",
      "2. Input: Image 3 (black and white checkerboard)\n",
      "   Output: Image 4 (green and yellow gradient)\n",
      "\n",
      "3. Input: Image 5 (black and white checkerboard)\n",
      "   Output: Image 6 (green and yellow gradient)\n",
      "\n",
      "4. Input: Image 7 (black and white checkerboard)\n",
      "   Output: Image 8 (green and yellow gradient)\n",
      "\n",
      "From the above analysis, we can observe that the pattern involves replacing the black squares with a gradient of green and yellow. Now, let's apply this pattern to the test input (Image 9):\n",
      "\n",
      "Test Input: Image 9 (black and white checkerboard)\n",
      "\n",
      "Following the pattern, we replace the black squares with a gradient of green and yellow. The output should have a 3 x 3 grid with the following colors:\n",
      "\n",
      "0: black\n",
      "1: green\n",
      "2: yellow\n",
      "3: green\n",
      "4: yellow\n",
      "5: green\n",
      "6: yellow\n",
      "7: green\n",
      "8: yellow\n",
      "9: black\n",
      "\n",
      "So, the output should be a 3 x 3 grid with the colors 0: black, 1: green, 2: yellow, 3: green, 4: yellow, 5: green, 6: yellow, 7: green, 8: yellow, 9: black.\n"
     ]
    }
   ],
   "source": [
    "#image_paths = []\n",
    "#for root, dirs, files in os.walk(\"./images_for_vllm/\", topdown=False):\n",
    "#   for name in files:\n",
    "#      image_paths.append(os.path.join(root, name))\n",
    "\n",
    "images = [Image.open(i) for i in image_paths]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(prompt, images, return_tensors=\"pt\")\n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 1000, \n",
    "    #\"temperature\": 0.0, \n",
    "    #\"do_sample\": False, \n",
    "}\n",
    "\n",
    "generate_ids = model.generate(\n",
    "    **inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    ")\n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(\n",
    "    generate_ids, \n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")[0]\n",
    "\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:49:41.173786Z",
     "start_time": "2024-09-24T01:37:50.517596Z"
    }
   },
   "id": "3c1c07a2f5c6d50f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4cc5e7813ffb5eb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
